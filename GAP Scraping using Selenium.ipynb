{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19a98d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dae094c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the URL of the Gap Bestsellers website\n",
    "url1 = \"https://www.gap.com/browse/category.do?cid=3024420&nav=meganav%3AMen%3AJust%20Arrived%3ABestsellers\"\n",
    "url = \"https://www.gap.com/browse/category.do?cid=13658#pageId=0&mlink=5643,20012060,DP_1_W_Dresses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52faf79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"product-card\")))\n",
    "\n",
    "# Scroll down to load all products (you may need to adjust the number of scrolls)\n",
    "for _ in range(5):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    WebDriverWait(driver, 5).until(EC.invisibility_of_element_located((By.CLASS_NAME, \"loading-spinner\")))\n",
    "\n",
    "# Get the page source after scrolling\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Create BeautifulSoup object\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all divs with the specified class\n",
    "product_divs = soup.find_all('div', class_='cat_product-image category-page-mvez9e')\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "product_links = []\n",
    "product_names = []\n",
    "\n",
    "# Iterate through product divs\n",
    "for product_div in product_divs:\n",
    "    # Find the anchor tag inside the div\n",
    "    anchor_tag = product_div.find('a')\n",
    "    \n",
    "    # Extract link\n",
    "    product_link = anchor_tag['href']\n",
    "    product_links.append(product_link)\n",
    "    \n",
    "    # Extract product name\n",
    "    product_name = anchor_tag.img['alt']\n",
    "    product_names.append(product_name)\n",
    "\n",
    "# Create a dictionary with the data\n",
    "data = {\n",
    "    'Product Name': product_names,\n",
    "    'Product Link': product_links\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "product_catalogue = pd.DataFrame(data)\n",
    "\n",
    "# Initialize an empty DataFrame to store the review data\n",
    "df = pd.DataFrame(columns=[\"product_url\", \"product_name\", \"review_heading\", \"review_description\", \"rating\"])\n",
    "\n",
    "# Loop through each product URL\n",
    "for product in product_links:\n",
    "    driver.get(product)\n",
    "    index = product_links.index(product)\n",
    "\n",
    "    # Scroll down to load reviews (you may need to adjust the scroll and sleep times)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(15)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the page source after scrolling\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find review headings, descriptions, and ratings\n",
    "    review_headings = []\n",
    "    review_headers = soup.find_all('h2', attrs={'class': 'pr-rd-review-headline'})\n",
    "    for header in review_headers:\n",
    "        text = header.get_text()\n",
    "        review_headings.append(text)\n",
    "\n",
    "    review_descriptions = []\n",
    "    review_desc = soup.find_all('p', attrs={'class': \"pr-rd-description-text\", 'lang' : \"en\"})\n",
    "    for desc in review_desc:\n",
    "        text = desc.get_text()\n",
    "        review_descriptions.append(text)\n",
    "\n",
    "    ratings = []\n",
    "    stars = soup.find_all('div', attrs={'class': 'pr-rd-star-rating'})\n",
    "    for star in stars:\n",
    "        text = star.get_text()\n",
    "        ratings.append(text)\n",
    "\n",
    "    # Create a DataFrame for the current product's reviews\n",
    "    product_df = pd.DataFrame({\n",
    "        \"product_name\": [product_names[index]] * len(review_headings),\n",
    "        \"review_heading\": review_headings,\n",
    "        \"review_description\": review_descriptions,\n",
    "        \"rating\": ratings,\n",
    "        \"product_url\": [product] * len(review_headings)\n",
    "    })\n",
    "\n",
    "    # Append the product's reviews to the main DataFrame\n",
    "    df = pd.concat([df, product_df], ignore_index=True)\n",
    "\n",
    "# Close the web driver\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "71ae9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('GAP_Bestsellers_Women_Reviews.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
